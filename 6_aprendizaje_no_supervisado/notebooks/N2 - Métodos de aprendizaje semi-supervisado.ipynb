{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"N2 - Métodos de aprendizaje semi-supervisado.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NnyNgqjZ2J6z"},"source":["<center><h1>N2: Aprendizaje semi-supervisado</h1></center>"]},{"cell_type":"markdown","metadata":{"id":"gsc32HMtc6TU"},"source":["# N2: Métodos de aprendizaje semi-supervisado\n"]},{"cell_type":"markdown","metadata":{"id":"MAsz003KMbmS"},"source":["# RECUERDA RELLENAR TUS DATOS A CONTINUACIÓN ANTES DE HACER NADA"]},{"cell_type":"code","metadata":{"id":"2xBNEFw1HJxS","executionInfo":{"status":"ok","timestamp":1615679693149,"user_tz":300,"elapsed":1121,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["# ===============================================================#\n","# Rellena AQUÍ tu nombre y apellidos antes de hacer nada\n","# ===============================================================#\n","\n","NOMBRE = 'CarlosEsteban'\n","APELLIDOS = 'PosadaMejia'\n","\n","# ===============================================================#\n","# NO MODIFIQUES ESTA PORCIÓN DE CÓDIGO, ES PARA LA EVALUACIÓN\n","# MUY IMPORTANTE: NO MODIFICAR\n","# ===============================================================#\n","from matplotlib.backends.backend_agg import FigureCanvasAgg\n","def encode_figure(fig):\n","    canvas = FigureCanvasAgg(fig)\n","    canvas.draw()\n","    img, (width, height) = canvas.print_to_buffer()\n","    return {'img': img, 'width': width, 'height': height}\n","\n","answers = {}\n","answers['name'] = NOMBRE\n","answers['surname'] = APELLIDOS\n","answers['subject'] = '06MAIR_10_A_2020-21_ANS'\n","answers['ex'] = 'N2'\n","# ===============================================================#"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KuhXGlHQLUcK"},"source":["En esta práctica aprenderemos a llevar a cabo un aprendizaje semi-supervisado. En concreto, estudiaremos el funcionamiento y la utilización del popular algoritmo de EM para aprender un modelo naive Bayes en semi-supervisado, así como la estrategia de aprendizaje conocida como \"co-training\".\n","\n","Empezaremos por programar una implementación del clasificador que usaremos, el clásico Naive Bayes. Este clasificador probabilístico guarda los parámetros relativos a la distribución de probabilidad marginal de clase ($\\{p(C=c)\\}_{c=1}^{|C|}$) y las distribuciones de probabilidad condicional de las variables predictoras dada la clase ($\\{p(X_i=x_i|C=c)\\}_{x_i=1}^{|X_i|}$ para los diferentes valores de la variable clase $C=c$ y para todas las variables predictoras). Con estos parámetros se puede calcular la probabilidad de un caso, $\\mathbf{x}$:\n","$$  p(C=c|\\mathbf{x})\\propto p(C=c)\\prod_{i=1}^{v} p(x_i|C=c)$$\n","normalizándolos para todos los posibles valores de $c$ (todas las clases posibles) y \n","con $v$ siendo el número de variables predictoras \n","(2 en este caso) para que la \n","suma sea $\\sum_{c=1}^{|C|} p(C=c|\\mathbf{x})=1$.\n","\n","Por conveniencia, también guardaremos otras variables como la cardinalidad de las diferentes variables y el índice de la variable clase.\n"]},{"cell_type":"code","metadata":{"id":"dC1zvNvdGZJ-","executionInfo":{"status":"ok","timestamp":1615679782021,"user_tz":300,"elapsed":367,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["import numpy as np\n","\n","class naiveBayes:\n","    def __init__(self, iClass, cardinalities):\n","        self.iClass = iClass\n","        self.cardinalities = cardinalities.copy()\n","        self.Pc = np.zeros(cardinalities[iClass])\n","        self.Pxc = []\n","        for i in np.arange(len(self.cardinalities)):\n","            aux = np.array([])\n","            if i != iClass:\n","                aux = np.zeros((cardinalities[i],cardinalities[iClass]))\n","            self.Pxc.append(aux)    "],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OiUdRZl3GZKB"},"source":["Una vez diseñado, vamos a lo importante. Un clasificador ha de \n","poder ser aprendido y usado para predecir. Por ello, diseñaremos \n","una función para cada procedimiento. \n","Para predecir, se han de calcular las siguiente probabilidades:\n","$$ p(C=c)\\prod_{i=1}^{v} p(x_i|C=c)$$\n","para todos los posibles valores de $c$ (todas las clases posibles) y \n","con $v$ siendo el número de variables predictoras \n","(2 en este caso). Finalmente, normalizamos para que la \n","suma de $\\sum_{c=1}^{|C|} p(C=c|x)=1$.\n","La función de predicción \n","sería así:"]},{"cell_type":"code","metadata":{"id":"KO-NXt6bGZKB","executionInfo":{"status":"ok","timestamp":1615679827469,"user_tz":300,"elapsed":412,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["def predictNB(model, instance):\n","    probs = model.Pc.copy()\n","    for i in np.arange(len(model.cardinalities)):\n","        if i != model.iClass:\n","            probs *= model.Pxc[i][instance[i],:]\n","\n","    return probs/np.sum(probs)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yd-hVE2nGZKD"},"source":["\n","Considerando la estructura definida para guardar los \n","parámetros y lo visto en clase sobre aprendizaje de \n","parámetros de máxima verosimilitud en un entorno de \n","aprendizaje semi-supervisado, diseñaremos la función \n","de aprendizaje:\n"]},{"cell_type":"code","metadata":{"id":"TCJclM_eGZKE","executionInfo":{"status":"ok","timestamp":1615679909201,"user_tz":300,"elapsed":447,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["def learnNB(L, U, pesosU, iClass, cardinalities, smoothing=1):\n","    modelo = naiveBayes(iClass, cardinalities)\n","    \n","    # Aprender de casos etiquetados\n","    for i in np.arange(L.shape[0]):\n","        # Actualizamos los parametros de la marginal P(c)\n","        modelo.Pc[L[i,iClass]] += 1\n","        \n","        for j in np.arange(len(cardinalities)):\n","            if j != iClass:\n","                # Actualizamos los parametros de las condicionales P(x_i|c)\n","                modelo.Pxc[j][L[i,j],L[i,iClass]] += 1\n","\n","    # Aprender de casos no etiquetados\n","    for u in np.arange(U.shape[0]):\n","        # Actualizamos los parametros de la marginal de P(c)\n","        modelo.Pc += pesosU[u,:]\n","        \n","        for j in np.arange(len(cardinalities)):\n","            if j != iClass:\n","                # Actualizamos los parametros de las condicionales P(x_i|c)\n","                modelo.Pxc[j][U[u,j],:] += pesosU[u,:]\n","    \n","    modelo.Pc += smoothing # Laplace smoothing\n","    modelo.Pc /= np.sum(modelo.Pc)\n","    for j in np.arange(len(cardinalities)):\n","        if j != iClass:\n","            modelo.Pxc[j] += smoothing # Laplace smoothing\n","            modelo.Pxc[j] /= np.sum(modelo.Pxc[j],0)\n","    \n","    return modelo"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s0gAgKMGZKG"},"source":["\n","Con esto completamos el diseño del clasificador Naive Bayes para el entorno semi-supervisado.\n","\n","Ahora ya podemos crear el algoritmo EM, que itera los pasos E y M de forma sencilla hasta que converge.\n","\n","**NOTA**: os recomiendo que primero os leáis todo el notebook y luego tratéis de completar el código que falta.\n"]},{"cell_type":"code","metadata":{"id":"E84pZbSlGZKH","executionInfo":{"status":"ok","timestamp":1615680320583,"user_tz":300,"elapsed":364,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["def EM(L, U, iClass, cardinalities, epsilon=0.001):\n","    modelo, pesosU = inicializar(L, U, iClass, cardinalities)\n","\n","    convergencia = False\n","    it = 0\n","    while not convergencia:\n","        it += 1\n","        print('Iteracion', it)\n","        # PASO E\n","        pesosU = EStep(L, U, pesosU, modelo)\n","\n","        antModelo = modelo\n","        \n","        # PASO M\n","        modelo = MStep(L, U, pesosU, iClass, cardinalities, antModelo)## Tu código aquí ##\n","    \n","        # Comprobacion de convergencia\n","        convergencia = testConvergencia(modelo, antModelo, epsilon)\n","    \n","    return modelo, pesosU"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cEVt6eblGZKI"},"source":["Faltarían por programar las tres funciones fundamentales \n","del EM: el paso E (<b>EStep</b>),  el paso M (<b>MStep</b>) \n","y la función que comprueba la convergencia (<b>testConvergencia</b>). \n","Además, falta la inicialización donde asignamos valores iniciales \n","a los pesos de las instancias no etiquetadas para aprender la \n","primera versión del modelo. En concreto, en esta ocasión \n","asignaremos a todos los casos la misma probabilidad de \n","pertenecer a cualquier clase:\n"]},{"cell_type":"code","metadata":{"id":"b9TlqyXMGZKJ","executionInfo":{"status":"ok","timestamp":1615680321993,"user_tz":300,"elapsed":359,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["def inicializar(L, U, iClass, cardinalities):\n","    # Todos los elementos en U tienen la misma probabilidad de pertenecer a cualquier clase\n","    pesosU = np.ones((U.shape[0],cardinalities[iClass]))\n","    pesosU /= cardinalities[iClass]\n","    \n","    modelo = learnNB(L, U, pesosU, iClass, cardinalities)\n","\n","    return modelo, pesosU"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LVjlJx2iGZKL"},"source":["\n","El paso E consiste en recalcular los pesos dado un modelo y el paso M en aprender una nueva versión del modelo:\n","    "]},{"cell_type":"code","metadata":{"id":"p6HfP-8MGZKM","executionInfo":{"status":"ok","timestamp":1615680323071,"user_tz":300,"elapsed":372,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["def EStep(L, U, pesosU, modelo):\n","    nPesosU = np.zeros(pesosU.shape)\n","    for u in np.arange(U.shape[0]):\n","        nPesosU[u,:] = predictNB(modelo, U[u,:])\n","\n","    return nPesosU\n","\n","def MStep(L, U, pesosU, iClass, cardinalities, antModelo):\n","    modelo = learnNB(L, U, pesosU, iClass, cardinalities)\n","    return modelo"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-Svk_i6GZKN"},"source":["\n","Mediremos la convergencia atendiendo al criterio de si \n","la distancia euclídea entre los parámetros del paso anterior \n","y del actual es menor que <i>epsilon</i> o no:\n"]},{"cell_type":"code","metadata":{"id":"PvTHXKRaGZKO","executionInfo":{"status":"ok","timestamp":1615680324999,"user_tz":300,"elapsed":334,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["def testConvergencia(modeloA, modeloB, epsilon=0.001):\n","    resultado = np.sum((modeloA.Pc-modeloB.Pc)**2)\n","\n","    for j in np.arange(len(modeloA.cardinalities)):\n","        if j != modeloA.iClass:\n","            resultado += np.sum((modeloA.Pxc[j]-modeloB.Pxc[j])**2)\n","  \n","    resultado = np.sqrt(resultado)\n","    \n","    return resultado < epsilon"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VtmETMBGZKQ"},"source":["\n","Una vez hemos diseñado completamente el algoritmo EM y el clasificador NB, podemos proceder a su uso. \n","Creamos un dataset y hacemos la llamada al EM:\n"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ZBQyKD3VGZKQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615680375760,"user_tz":300,"elapsed":1455,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}},"outputId":"4e90b6a9-6781-4dd6-8944-545d9115b4d1"},"source":["from sklearn.datasets import make_classification\n","\n","np.random.seed(23)\n","nPredVars = 10\n","iClass = nPredVars\n","nSampleXsubset = 20\n","cardinalities = np.repeat(2,nPredVars+1)\n","\n","# Simulamos un dataset\n","X,y = make_classification(n_samples=nSampleXsubset*3,n_features=nPredVars,n_redundant=0)\n","X[X<0] = 0;X[X>0] = 1 # discretizamos las variables predictoras\n","X = X.astype(int)\n","y.shape=(len(y),1)\n","\n","L = np.concatenate((X[:nSampleXsubset,:],\n","                    y[:nSampleXsubset,:]),axis=1)\n","U = np.concatenate((X[nSampleXsubset:(nSampleXsubset*2),:],\n","                    y[nSampleXsubset:(nSampleXsubset*2),:]),axis=1)\n","U[:,iClass] = np.nan # eliminamos la etiqueta de un subconjunto de elementos\n","\n","modelo, pesos = EM(L, U, iClass, cardinalities, 0.001)\n","\n","# INICIO - NO TOCAR : necesario para la evaluación del notebook\n","answers['1'] = {'modelo': modelo,\n","                'pesos': pesos}\n","# FIN - NO TOCAR : necesario para la evaluación del notebook"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Iteracion 1\n","Iteracion 2\n","Iteracion 3\n","Iteracion 4\n","Iteracion 5\n","Iteracion 6\n","Iteracion 7\n","Iteracion 8\n","Iteracion 9\n","Iteracion 10\n","Iteracion 11\n","Iteracion 12\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XCx7uOQdGZKS"},"source":["\n","Como en anteriores ocasiones, podemos estudiar la bondad del agrupamiento ya que se conoce la realidad:\n"]},{"cell_type":"code","metadata":{"id":"PmDsV_EhGZKT","executionInfo":{"status":"ok","timestamp":1615680383893,"user_tz":300,"elapsed":367,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["test = np.concatenate((X[nSampleXsubset*2:,:],\n","                    y[nSampleXsubset*2:,:]),axis=1)\n","\n","realLabels = test[:,iClass]\n","predLabels = np.zeros(realLabels.shape)\n","for i in np.arange(test.shape[0]):\n","    probs = predictNB(modelo, test[i,:])\n","    predLabels[i] = np.argmax(probs)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzrzqaxFGZKU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615680386769,"user_tz":300,"elapsed":383,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}},"outputId":"a38706af-9576-4bc7-ea38-4f23b6d808fa"},"source":["def matriz_confusion(cat_real, cat_pred, nClasses):\n","    mat = np.array([[np.sum(np.logical_and(cat_real==i, cat_pred==j)) \n","                     for j in np.arange(nClasses)] \n","                    for i in np.arange(nClasses)])\n","    return(mat)\n","\n","def medida_error(mat):\n","    tot = np.sum(mat)\n","    aux = mat.copy()\n","    np.fill_diagonal(aux, 0)\n","    return float(np.sum(aux))/tot\n","\n","def medida_precision(mat, l, k):\n","    return mat[l,k]/float(np.sum(mat[:,k]))\n","\n","def medida_recall(mat, l, k):\n","    return mat[l,k]/float(np.sum(mat[l,:]))\n","\n","def medida_f1(mat):\n","    prec = medida_precision(mat, 1, 1)\n","    rec = medida_recall(mat, 1, 1)\n","    if (prec+rec)==0:\n","        return 0\n","    else:\n","        return 2*prec*rec/(prec+rec)\n","\n","mC = matriz_confusion(realLabels,predLabels,cardinalities[iClass])\n","\n","print(mC)\n","print('El error del clasificador es = ', medida_error(mC))\n","print('El valor F1 del clasificador es = ', medida_f1(mC))\n","\n","# INICIO - NO TOCAR : necesario para la evaluación del notebook\n","answers['1'] = {'mC': mC}\n","# FIN - NO TOCAR : necesario para la evaluación del notebook"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[9 2]\n"," [3 6]]\n","El error del clasificador es =  0.25\n","El valor F1 del clasificador es =  0.7058823529411765\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p2YP7FF3GZKW"},"source":["<hr>\n","<h2>Implementaciones en librerías de Python</h2>\n","\n","La librería ScikitLearn implementa diversas versiones del clasificador NB. En el caso de <b>MultinomialNB</b>, la distribución de probabilidad que se modela es diferente: una distribución de probabilidad multinomial donde el valor de cada variable predictora es el conteo de esta distribución de probabilidad:\n","\n","\\begin{aligned}\n","\\Pr(X_{1}=x_{1},\\dots, X_{v}=x_{v})&{}={\\begin{cases}{\\displaystyle {n! \\over x_{1}!\\cdot\\dots\\cdot x_{k}!}p_{1}^{x_{1}}\\cdot \\dots \\cdot p_{v}^{x_{v}}},\\quad &{\\text{when }}\\sum _{i=1}^{k}x_{i}=n\\\\\\\\0&{\\text{otherwise,}}\\end{cases}}\n","\\end{aligned}\n","para cualquier conjunto $\\{x_1, \\dots, x_v\\}$ de valores no negativos.\n","\n","Si quisiésemos incluir esta versión del NB en el algoritmo EM, deberíamos modificar las funciones específicas que hacen llamadas al modelo pero no la general iterativa del EM.\n","\n","En primer lugar, deberíamos preparar una función para el aprendizaje del modelo cuando los datos son semi-supervisados:\n"]},{"cell_type":"code","metadata":{"id":"a2OIpOIpGZKX","executionInfo":{"status":"ok","timestamp":1615680402502,"user_tz":300,"elapsed":666,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["from sklearn.naive_bayes import MultinomialNB\n","\n","def sklearnNB(L, U, pesosU, iClass, cardinalities):\n","    modelo = MultinomialNB()\n","\n","    modelo.partial_fit(np.delete(L, iClass, axis=1),\n","                       L[:,iClass],\n","                       classes=[0,1])\n","\n","    for c in np.arange(cardinalities[iClass]):\n","        impU = U.copy()\n","        impU[:,iClass] = c\n","        modelo.partial_fit(np.delete(impU, iClass, axis=1),\n","                           impU[:,iClass],\n","                           sample_weight = pesosU[:,c])\n","\n","    return modelo"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KmYUnYhcGZKZ"},"source":["\n","La función de predicción del NB, en este caso, ya está integrada en la definición de la clase de Scikit-learn.\n","\n","Las cuatro funciones auxiliares del EM se deben adecuar a este nuevo modelo: \n"]},{"cell_type":"code","metadata":{"id":"yLJLlG8kGZKZ","executionInfo":{"status":"ok","timestamp":1615680409692,"user_tz":300,"elapsed":419,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["def inicializar(L, U, iClass, cardinalities):\n","    pesosU = np.ones((U.shape[0],cardinalities[iClass]))\n","    pesosU /= cardinalities[iClass]\n","    \n","    modelo = sklearnNB(L, U, pesosU, iClass, cardinalities)\n","\n","    return modelo, pesosU\n","\n","def EStep(L, U, pesosU, modelo):\n","\n","    nPesosU = modelo.predict_proba(np.delete(U, iClass, axis=1))\n","\n","    return nPesosU\n","\n","def MStep(L, U, pesosU, iClass, cardinalities, antModelo):\n","    modelo = sklearnNB(L, U, pesosU, iClass, cardinalities)\n","    return modelo\n","\n","def testConvergencia(modeloA, modeloB, epsilon=0.001):\n","    resultado = np.sum((np.exp(modeloA.class_log_prior_) - \n","                        np.exp(modeloB.class_log_prior_))**2)\n","    resultado += np.sum((np.exp(modeloA.feature_log_prob_) - \n","                         np.exp(modeloB.feature_log_prob_))**2)\n","\n","    resultado = np.sqrt(resultado)\n","    \n","    return resultado < epsilon"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KTSRyNpWGZKb"},"source":["\n","Una vez hemos diseñado completamente las distintas funciones del algoritmo EM y esta nueva versión del NB, podemos proceder a su uso. \n","Creamos un dataset y hacemos la llamada al EM:\n"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"_ILFM6uBGZKb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615680412193,"user_tz":300,"elapsed":362,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}},"outputId":"958d3c67-f700-43c7-ac09-b5941513a3cf"},"source":["np.random.seed(23)\n","nPredVars = 10\n","iClass = nPredVars\n","nSampleXsubset = 20\n","cardinalities = np.repeat(2,nPredVars+1)\n","\n","# Simulamos un dataset\n","X,y = make_classification(n_samples=nSampleXsubset*3,n_features=nPredVars,n_redundant=0)\n","X[X<0] = 0;X[X>0] = 1 # discretizamos las variables predictoras\n","X = X.astype(int)\n","y.shape=(len(y),1)\n","\n","L = np.concatenate((X[:nSampleXsubset,:],\n","                    y[:nSampleXsubset,:]),axis=1)\n","U = np.concatenate((X[nSampleXsubset:(nSampleXsubset*2),:],\n","                    y[nSampleXsubset:(nSampleXsubset*2),:]),axis=1)\n","U[:,iClass] = np.nan\n","\n","skmodelo, skpesos = EM(L, U, iClass, cardinalities, 0.001)\n","print(skpesos)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Iteracion 1\n","Iteracion 2\n","Iteracion 3\n","Iteracion 4\n","Iteracion 5\n","Iteracion 6\n","[[0.37452499 0.62547501]\n"," [0.20208038 0.79791962]\n"," [0.4381833  0.5618167 ]\n"," [0.61770176 0.38229824]\n"," [0.53587632 0.46412368]\n"," [0.52671695 0.47328305]\n"," [0.46247666 0.53752334]\n"," [0.29304468 0.70695532]\n"," [0.48819531 0.51180469]\n"," [0.34138085 0.65861915]\n"," [0.56828363 0.43171637]\n"," [0.22954694 0.77045306]\n"," [0.63735359 0.36264641]\n"," [0.42909102 0.57090898]\n"," [0.21850953 0.78149047]\n"," [0.52680548 0.47319452]\n"," [0.66058945 0.33941055]\n"," [0.460702   0.539298  ]\n"," [0.52071844 0.47928156]\n"," [0.6150956  0.3849044 ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oMlhIDZRGZKd","executionInfo":{"status":"ok","timestamp":1615680416227,"user_tz":300,"elapsed":396,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["test = np.concatenate((X[nSampleXsubset*2:,:],\n","                       y[nSampleXsubset*2:,:]),axis=1)\n","\n","skRealLabels = test[:,iClass]\n","skPredLabels = np.zeros(realLabels.shape)\n","test = np.delete(test,iClass,1)\n","skPredLabels = np.argmax(skmodelo.predict_proba(test), axis=1)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhhYcLL0GZKf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615680417763,"user_tz":300,"elapsed":344,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}},"outputId":"30ae595c-8c90-4077-da73-80c006b84635"},"source":["mC = matriz_confusion(skRealLabels,skPredLabels,cardinalities[iClass])\n","\n","print(mC)\n","print('El error del clasificador es = ', medida_error(mC))\n","print('El valor F1 del clasificador es = ', medida_f1(mC))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[[7 4]\n"," [2 7]]\n","El error del clasificador es =  0.3\n","El valor F1 del clasificador es =  0.7000000000000001\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6KZccc47GZKg"},"source":["\n","El algoritmo EM, ejecutado en una única ocasión, puede dar un resultado no óptimo: se está eligiendo una inicialización que lleva al algoritmo a encallar en un óptimo local. Si se ejecuta en varias ocaciones, eventualmente se obtendrá el resultado óptimo.\n","\n","Podríamos comparar el resultado de nuestro algoritmo y el de la implementación de ScikitLearn para observar si devuelven el mismo resultado:\n","    "]},{"cell_type":"code","metadata":{"id":"iDV-mOjpGZKh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615680453340,"user_tz":300,"elapsed":367,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}},"outputId":"b83d9aac-2c55-4a44-bb35-87d3c1fc9aec"},"source":["# Si comparamos el resultado de ambos algoritmos, el nuestro y el de ScikitLearn\n","mC_comp = matriz_confusion(predLabels,skPredLabels,cardinalities[iClass])\n","\n","print('Matriz de confusión:')\n","print(mC_comp)\n","print('El valor del error (diferencia) es = ', medida_error(mC_comp))\n","print('El valor F1 del clasificador es = ', medida_f1(mC_comp))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Matriz de confusión:\n","[[9 3]\n"," [0 8]]\n","El valor del error (diferencia) es =  0.15\n","El valor F1 del clasificador es =  0.8421052631578948\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3b1oNgb7-iR_","executionInfo":{"status":"ok","timestamp":1615680576386,"user_tz":300,"elapsed":337,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}}},"source":["# PREGUNTAS:\n","\n","# 1. Al utilizar Naive Bayes estamos realizando varias asunciones, una de ellas, muy importante, relacionada con nuestras variables. ¿Cuál es esta asunción?\n","\n","# a) Que nuestras variables esten escaladas en el mismo rango\n","# b) Que nuestras variables son independientes unas de otras\n","# c) Que nuestras variables no contengan valores nulos\n","\n","respuesta1 = 'b'\n","\n","# 2. ¿Qué ventaja hay en usar EM NB respecto a Naive Bayes?\n","\n","# a) El proceso de aprendizaje es más rápido gracias al algoritmo de EM\n","# b) El algoritmo de EM permite poder entrenar un modelo aún cuando no disponemos de todas las etiquetas\n","# c) Permite relajar la condición de la independencia de las variables\n","\n","respuesta2 = 'b'\n","\n","# INICIO - NO TOCAR : necesario para la evaluación del notebook\n","answers['2'] = {'respuesta': respuesta1}\n","answers['3'] = {'respuesta': respuesta2}\n","# FIN - NO TOCAR : necesario para la evaluación del notebook"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QIDVtnFEbYvs"},"source":["# RECUERDA EJECUTAR ESTA CELDA ÚNICAMENTE CUANDO HAYAS FINALIZADO EL NOTEBOOK"]},{"cell_type":"code","metadata":{"id":"9mvQijM9bYvs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615680579393,"user_tz":300,"elapsed":846,"user":{"displayName":"carlos posada","photoUrl":"","userId":"07531513090733992391"}},"outputId":"b237d0ae-e1ad-4db4-f4f0-86abda25f6f4"},"source":["################################################################################\n","# ATENCIÓN, MUY IMPORTANTE: EJECUTA ESTA CELDA SIN MODIFICAR NADA!\n","#\n","# ESTA CELDA SE ENCARGA DE COMPRIMIR LOS RESULTADOS OBTENIDOS Y MANDARLOS\n","# AL SERVIDOR PARA SU VERIFICACIÓN Y ALMACENAJE.\n","#\n","# SI NO LA EJECUTAS, ¡¡¡NO PODRÁS SER EVALUADX!!!\n","################################################################################\n","\n","import zmq\n","import base64\n","import pickle\n","import bz2\n","import sys\n","\n","def send_results(answers):\n","\n","    def compress_data(data):\n","        data_pkl = pickle.dumps(data)\n","        data_bz2 = bz2.compress(data_pkl)\n","        return data_bz2\n","\n","    if NOMBRE == 'TuNombre' or APELLIDOS == 'TusApellidos' or \\\n","    NOMBRE.strip() == '' or APELLIDOS.strip() == '':\n","        print('Rellena tu nombre y apellidos en la primera celda del notebook!')\n","    else:\n","        print('Conectando con el servidor de evaluación...', end='\\t')\n","        context = zmq.Context()\n","        socket = context.socket(zmq.REQ)\n","        socket.connect(base64.b64decode(b'dGNwOi8vMTU4LjQyLjE3MC4xMzU6MzM4OQ==').decode('ascii'))\n","        print('OK')\n","\n","        # Compressing data\n","        print('Comprimiendo las respuestas...', end='\\t')\n","        data = compress_data(answers)\n","        print('OK')\n","\n","        print('Enviando datos...', end='\\t')\n","        socket.send(data)\n","        message = socket.recv()\n","        if message == data:\n","            print(f'OK')\n","            print('Entrega realizada con éxito! :)')\n","        else:\n","            print('ERROR! Por favor vuelve a ejecutar la celda. Si los problemas persisten ponte en contacto con el profesor.')    \n","\n","\n","send_results(answers)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Conectando con el servidor de evaluación...\tOK\n","Comprimiendo las respuestas...\tOK\n","Enviando datos...\tOK\n","Entrega realizada con éxito! :)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dIjUNEJfESOk"},"source":[""],"execution_count":null,"outputs":[]}]}