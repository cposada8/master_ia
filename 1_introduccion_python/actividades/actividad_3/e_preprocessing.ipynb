{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../configs/')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with this line I have access to original headers as lists\n",
    "from utils import load_train_datasets, load_test_datasets, print_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = \"../../DataHackaton/train/\"\n",
    "path2test = \"../../DataHackaton/test/\"\n",
    "path2target = \"../targets/\"\n",
    "path2features = \"../features/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davinchi/Documents/hackaton2020/venv/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "candidates_df, vacants_df, application_df, app_stages_df, stages_df,_ = load_datasets(path2train)\n",
    "candidates_test_df, vacants_test_df, application_test_df, stages_test_df,_ = load_datasets(path2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "videosize_df = pd.read_csv(f\"{path2features}videosize.csv\").set_index(\"id\")\n",
    "# videosize_df_test = pd.read_csv(f\"{path2features}videosize.csv\").set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de la variable target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(path_to_target):\n",
    "    # path_to_target : path to save the target variable\n",
    "\n",
    "    app_stage = app_stages_df.join(stages_df, on=\"stage_id\")\n",
    "    app_stage[\"afin\"] = (app_stage[\"status\"] == \"accepted\") & ((app_stage[\"stage_type\"]==0) |(app_stage[\"stage_type\"]==1))\n",
    "    app_stage[\"afin\"] = app_stage[\"afin\"].astype(int)\n",
    "    app_stage = app_stage.loc[:,[\"application_id\", \"stage_id\", \"vacant_id\", \"afin\"]].reset_index()\n",
    "    app_stage = app_stage.rename(columns={\"id\": \"app_stage_id\"})\n",
    "\n",
    "    app_id_afin = pd.DataFrame(app_stage.groupby(\"application_id\")[\"afin\"].apply(lambda a: any(a)))\n",
    "    app_id_afin[\"afin\"] = app_id_afin[\"afin\"].astype(int)\n",
    "\n",
    "    app_id_afin.to_csv(f\"{path_to_target}app_id_afin.csv\")\n",
    "    print(f\"target created at {path_to_target}app_id_afin.csv\")\n",
    "    return app_id_afin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de la tabla de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creación de features en candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_cantidates(candidates_df, videosize=None, show_logs=False):\n",
    "    # this function computes some features over the Candidates dataframe\n",
    "    # it would also make a merge with videosize file if there is one\n",
    "    print_logs(\"Computing Features on candidates: ...\", show_logs)\n",
    "    \n",
    "    candidates_ft = candidates_df.copy()\n",
    "    \n",
    "    # 1. videosize\n",
    "    if videosize is not None:\n",
    "        candidates_ft = candidates_ft.merge(videosize, left_on=\"id\", right_on=\"id\")\n",
    "        print_logs(f\"computed videosize,  {candidates_ft.shape}\", show_logs)\n",
    "    \n",
    "    # 2. longitud descripción\n",
    "    candidates_ft[\"longitud_descripcion\"] = candidates_ft[\"profile_description\"].str.len()\n",
    "    print_logs(f\"computed longitud_descripcion  {candidates_ft.shape}\", show_logs)\n",
    "    \n",
    "    # 3. Cantidad estudios\n",
    "    candidates_ft[\"cantidad_estudios\"] = candidates_ft[\"studies\"].apply(lambda x: json.loads(x)).apply(len)\n",
    "    print_logs(f\"computed cantidad_estudios  {candidates_ft.shape}\", show_logs)\n",
    "    \n",
    "    # 4. Cantidad experiencias\n",
    "    candidates_ft[\"cantidad_experiences\"] = candidates_ft[\"experiences\"].apply(lambda x: json.loads(x)).apply(len)\n",
    "    print_logs(f\"computed cantidad_experiences  {candidates_ft.shape}\", show_logs)\n",
    "    \n",
    "    # 5. birth year\n",
    "    candidates_ft[\"birth_year\"] = pd.to_datetime(candidates_ft[\"birthdate\"], errors=\"coerce\").dt.year\n",
    "    print_logs(f\"computed birth_year  {candidates_ft.shape}\", show_logs)\n",
    "    \n",
    "    # 6. Availability to move\n",
    "    candidates_ft[\"available_to_move\"] = candidates_ft[\"available_to_move\"].fillna(0).astype(int)\n",
    "    print_logs(f\"changed: available to move  {candidates_ft.shape}\", show_logs)\n",
    "    \n",
    "    return candidates_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creación de features en vacants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_vacants(vacants_df, feature_cols, show_logs=False):\n",
    "    \n",
    "    print_logs(\"Computing Features on vacants: ...\", show_logs)\n",
    "    \n",
    "    vacants_ft = vacants_df.copy()\n",
    "    vacants_ft[\"titles_and_studies\"] = vacants_ft[\"titles_and_studies\"].str.lower()\n",
    "    \n",
    "    vacants_ft = vacants_ft[feature_cols]\n",
    "    print_logs(f\"shape of vacants_features:  {vacants_ft.shape}\", show_logs)\n",
    "    \n",
    "    return vacants_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creación features mixtas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_mixtas(features):\n",
    "    features[\"cumple_educacion\"] = (features[\"education_level_vac\"] == features[\"education_level\"]).astype(int)\n",
    "    features[\"cumple_salario\"] = ((features[\"salary\"] >= features[\"min_salary\"]) & \n",
    "                                    (features[\"salary\"] <= features[\"max_salary\"])).astype(int)\n",
    "    \n",
    "    ordered_education = ['Básica primaria',\n",
    "                     'Bachillerato (grados 6°, 7° u 8°)',\n",
    "                     'Bachillerato (grados 9°, 10° y 11°)',\n",
    "                     'Bachillerato completo',\n",
    "                     'Técnico',\n",
    "                     'Tecnólogo',\n",
    "                     'Profesional',\n",
    "                     'Especialización/ Maestría',\n",
    "                     'Doctorado']\n",
    "    \n",
    "    features[\"education_level\"] = pd.Categorical(features[\"education_level\"],\n",
    "                                            categories=ordered_education,\n",
    "                                            ordered=True)\n",
    "\n",
    "    features[\"education_level_vac\"] = pd.Categorical(features[\"education_level_vac\"],\n",
    "                                                categories=ordered_education,\n",
    "                                                ordered=True)\n",
    "    features[\"education_level_number\"] = features[\"education_level\"].cat.codes.replace(-1, np.nan)\n",
    "    features[\"education_level_vac_number\"] = features[\"education_level_vac\"].cat.codes.replace(-1, np.nan)\n",
    "\n",
    "    features[\"education_difference\"] = features[\"education_level_number\"] - features[\"education_level_vac_number\"]\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(train_or_test, cands, vacs, app, videosize):\n",
    "    candidates_features = create_features_cantidates(cands, videosize, True)\n",
    "    vacants_feature_cols = [\n",
    "        \"min_salary\", \n",
    "        \"max_salary\", \n",
    "        \"salary_type\", \n",
    "        \"education_level_vac\",\n",
    "        \"experience_and_positions\",\n",
    "        \"knowledge_and_skills\",\n",
    "        \"titles_and_studies\",\n",
    "        \"number_of_quotas\"\n",
    "    ]\n",
    "    vacants_features = create_features_vacants(vacs, vacants_feature_cols, True)\n",
    "    features = app[[ \"vacant_id\", \"candidate_id\"]].reset_index()\n",
    "\n",
    "    # rename the id column to application_id\n",
    "    features = features.rename(columns={\"id\": \"application_id\"})\n",
    "    # merge the base of features with candidates and vacants\n",
    "    features = features.merge(candidates_features, left_on= \"candidate_id\",  right_on=\"id\")\n",
    "    features = features.merge(vacants_features, left_on= \"vacant_id\",  right_on=\"id\")\n",
    "    features = create_features_mixtas(features)\n",
    "    cols2delete = [\n",
    "        \"email\", \n",
    "        \"first_name\", \n",
    "        \"last_name\", \n",
    "        \"phone\", \n",
    "        \"profile_description\", \n",
    "        \"has_video\",\n",
    "        \"studies\",\n",
    "        \"experiences\",\n",
    "        \"psy_tests\",\n",
    "        \"identification_number\",\n",
    "        \"country_birth\",\n",
    "        \"birthdate\",\n",
    "        \"civil_status\",\n",
    "        \"title_or_profession\"\n",
    "    ]\n",
    "    features= features.drop(cols2delete, axis=1)\n",
    "    if train_or_test == \"train\":\n",
    "        target = create_target(path2target)\n",
    "        dataset = features.merge(target, left_on=\"application_id\", right_on=\"application_id\", how=\"right\")\n",
    "    else:\n",
    "        dataset = features\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(\"train\", candidates_df, vacants_df, application_df, videosize_df)\n",
    "test_dataset = create_dataset(\"test\", candidates_test_df, vacants_test_df, application_test_df, videosize_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine vacants and candidates features\n",
    "* 1. Create features from vacants and candidates independently\n",
    "* 2. Combine them with the applications dataframe by vacant_id and candidate_id as keys\n",
    "* 3. Delete useless columns\n",
    "* 4. Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Features on candidates: ...\n",
      "computed videosize,  (548364, 23)\n",
      "computed longitud_descripcion  (548364, 24)\n",
      "computed cantidad_estudios  (548364, 25)\n",
      "computed cantidad_experiences  (548364, 26)\n",
      "computed birth_year  (548364, 27)\n",
      "changed: available to move  (548364, 27)\n"
     ]
    }
   ],
   "source": [
    "candidates_features = create_features_cantidates(candidates_df, videosize_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Features on vacants: ...\n",
      "shape of vacants_features:  (11693, 8)\n"
     ]
    }
   ],
   "source": [
    "vacants_feature_cols = [\n",
    "    \"min_salary\", \n",
    "    \"max_salary\", \n",
    "    \"salary_type\", \n",
    "    \"education_level_vac\",\n",
    "    \"experience_and_positions\",\n",
    "    \"knowledge_and_skills\",\n",
    "    \"titles_and_studies\",\n",
    "    \"number_of_quotas\"\n",
    "]\n",
    "vacants_features = create_features_vacants(vacants_df, vacants_feature_cols, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = application_df[[ \"vacant_id\", \"candidate_id\"]].reset_index()\n",
    "\n",
    "# rename the id column to application_id\n",
    "features = features.rename(columns={\"id\": \"application_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the base of features with candidates and vacants\n",
    "features = features.merge(candidates_features, left_on= \"candidate_id\",  right_on=\"id\")\n",
    "features = features.merge(vacants_features, left_on= \"vacant_id\",  right_on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = create_features_mixtas(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2delete = [\n",
    "    \"email\", \n",
    "    \"first_name\", \n",
    "    \"last_name\", \n",
    "    \"phone\", \n",
    "    \"profile_description\", \n",
    "    \"has_video\",\n",
    "    \"studies\",\n",
    "    \"experiences\",\n",
    "    \"psy_tests\",\n",
    "    \"identification_number\",\n",
    "    \"country_birth\",\n",
    "    \"birthdate\",\n",
    "    \"civil_status\",\n",
    "    \"title_or_profession\"\n",
    "]\n",
    "features= features.drop(cols2delete, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(path2features+\"features_on_vacants_and_candidates.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv(f\"{path2target}app_id_afin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_targets_and_features(targets, features):\n",
    "    # this function will merge the features for every index\n",
    "    # in targets dataframe. The key will be the application_id in\n",
    "    # the features and targets dataframes\n",
    "    \n",
    "    dataset = features.merge(targets, left_on=\"application_id\", right_on=\"application_id\", how=\"right\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = combine_targets_and_features(target_df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(path2features+\"dataset_feat_target.csv\", sep=\";\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pickle(path2features+\"dataset_feat_target.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
